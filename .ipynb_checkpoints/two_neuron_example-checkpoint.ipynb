{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two neuron example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p = int(2) #features\n",
    "n = int(10000) #examples\n",
    "\n",
    "## generate some features for training data\n",
    "X = np.random.rand(n,p)-0.5\n",
    "\n",
    "## generate labels of the feature vectors with known functions\n",
    "## Note that sign()/2+0.5 maps output to be 0 or 1, \n",
    "## which is the range of the activation fuction\n",
    "Y1 = np.sign(-2*X[:,[0]]+.2-X[:,[1]])/2+.5\n",
    "Y2 = np.sign(5*X[:,[0]]**3-X[:,[1]])/2+.5\n",
    "Y = np.hstack((Y1, Y2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training data for first classification problem\n",
    "plt.scatter(X[:,0], X[:,1], c=Y1.flatten())\n",
    "plt.title('Labeled data, first classification problem')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training data for second classification problem \n",
    "plt.scatter(X[:,0], X[:,1], c=Y2.flatten())\n",
    "plt.title('Labeled data, second classification problem')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train NN\n",
    "Xb = np.hstack((np.ones((n,1)), X))\n",
    "q = np.shape(Y)[1] #number of classification problems\n",
    "M = 3 #number of hidden nodes\n",
    "\n",
    "## initial weights\n",
    "W = np.random.randn(p+1, q);\n",
    "\n",
    "alpha = 0.1 #step size\n",
    "L = 10 #number of epochs\n",
    "\n",
    "def logsig(_x):\n",
    "    return 1/(1+np.exp(-_x))\n",
    "        \n",
    "for epoch in range(L):\n",
    "    ind = np.random.permutation(n)\n",
    "    for i in ind:\n",
    "        # Forward-propagate \n",
    "        Yhat = logsig(Xb[[i],:]@W) \n",
    "         # Backpropagate\n",
    "        delta = (Yhat-Y[[i],:])*Yhat*(1-Yhat)\n",
    "        Wnew = W - alpha*Xb[[i],:].T@delta\n",
    "        W = Wnew\n",
    "    print('epoch: ', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final predicted labels (on training data)\n",
    "H = logsig(np.hstack((np.ones((n,1)), Xb@W)))\n",
    "Yhat = logsig(Xb@W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=Yhat[:,0])\n",
    "plt.title('Predicted Labels, first classification problem')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=Yhat[:,1])\n",
    "plt.title('Predicted Labels, second classification problem')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_c1 = np.sum(abs(np.round(Yhat[:,0])-Y[:,0]))\n",
    "print('Errors, first classification problem:', err_c1)\n",
    "\n",
    "err_c2 = np.sum(abs(np.round(Yhat[:,1])-Y[:,1]))\n",
    "print('Errors, second classification problem:', err_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
