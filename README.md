# ğŸ“Š Matrix Methods in Machine Learning

This repository contains a collection of **machine learning practices** using matrix-based methods. The goal is to explore how matrix operations and optimization techniques are used in **classification, regression, dimensionality reduction, and deep learning**. Each notebook showcases an important aspect of **Matrix Methods in Machine Learning**, providing insights and practical implementations.

## ğŸ”¥ Skills Demonstrated
- **Kernel Methods & Support Vector Machines (SVM)**
- **LASSO Regression**
- **Matrix Methods in Machine Learning**
- **Optimization with Gradient Descent**
- **Principal Component Analysis (PCA)**
- **Singular Value Decomposition (SVD) & Eigenfaces**

## ğŸ“‚ Practice Highlights

Below are the featured practices in this portfolio, along with the machine learning methods applied and problems addressed:

### ğŸ“˜ **[Decision Boundary](./Python_code/01_linear_classiï¬er.ipynb)**

**Method Used:** Linear classification using decision boundaries.

**Problem Addressed:** Classifying data points into two categories using a linear decision boundary.

![](/results/01_linear_classiï¬er.png)

### ğŸ“˜ **[Linearly Independent](./Python_code/02_linearly_independent.ipynb)**

**Method Used:** Identifying linearly independent features for dimensionality reduction.

**Problem Addressed:** Determining which features in a dataset contribute unique information to improve model efficiency.

### ğŸ“˜ **[Polynomial Fitting](./Python_code/03_polynomial_ï¬tting.ipynb)**

**Method Used:** Polynomial regression for curve fitting.

**Problem Addressed:** Fitting a polynomial function to data points to capture nonlinear relationships.

![](/results/03_polynomial_ï¬tting.png)

### ğŸ“˜ **[Gram-Schmidt Orthogonalization](./Python_code/04_movies_rating.ipynb)**

**Method Used:** Matrix factorization for collaborative filtering.

**Problem Addressed:** Predicting user preferences in a movie rating system using latent factor models.

### ğŸ“˜ **[Happy/ Angry Classifier](./Python_code/05_happy_angry_classifier.ipynb)**

**Method Used:** Binary classification using facial emotion recognition.

**Problem Addressed:** Classifying images of faces into 'happy' or 'angry' emotions using machine learning.

### ğŸ“˜ **[Singular Value Decomposition (SVD)](./Python_code/06_SVD.ipynb)**

**Method Used:** Singular Value Decomposition (SVD) for feature extraction.

**Problem Addressed:** Reducing dimensionality while retaining essential data information for efficient computations.

![](/results/06_SVD.png)

### ğŸ“˜ **[Logistic Regression](./Python_code/07_logistic_regression.ipynb)**

**Method Used:** Logistic regression for binary classification.

**Problem Addressed:** Predicting binary outcomes based on input features, such as spam detection or disease prediction.

![](/results/07_logistic_regression.png)


### ğŸ“˜ **[LASSO Regression](./Python_code/08_LASSO.ipynb)**

**Method Used:** LASSO regression for feature selection and regularization.

**Problem Addressed:** Preventing overfitting while selecting the most important predictors in a dataset.

![](/results/08_LASSO.png)


### ğŸ“˜ **[Kernel Classification](./Python_code/09_kernel_classification.ipynb)**

**Method Used:** Kernel methods for nonlinear classification.

**Problem Addressed:** Classifying data with complex decision boundaries that are not separable using linear models.

![](/results/09_kernel_classification.png)


### ğŸ“˜ **[Kernel regression](./Python_code/10_kernel_regression.ipynb)**

**Method Used:** Kernel regression for function approximation.

**Problem Addressed:** Predicting continuous values using flexible nonlinear regression techniques.

![](/results/10_kernel_regression.png)

### ğŸ“˜ **[Support Vector Machine (SVM)](./Python_code/11_linear_svm.ipynb)**

**Method Used:** Support Vector Machine (SVM) for classification.

**Problem Addressed:** Finding the optimal hyperplane to separate classes with maximum margin.

![](/results/11_linear_svm.png)

### ğŸ“˜ **[Overfitting](./Python_code/12_linear_classifier_overfitting.ipynb)**

**Method Used:** Overfitting analysis in linear classification.

**Problem Addressed:** Understanding and mitigating overfitting in machine learning models.

![](/results/12_linear_classifier_overfitting.png)

### ğŸ“˜ **[K-Means Clustering](./Python_code/13_Kmeans_SVD.ipynb)**

**Method Used:** K-Means clustering combined with SVD for feature extraction.

**Problem Addressed:** Grouping similar data points into clusters while reducing feature dimensions.

### ğŸ“˜ **[Advanced K-Means clustering](./Python_code/13_Kmeans_SVD02.ipynb)**

**Method Used:** Advanced K-Means clustering with SVD.

**Problem Addressed:** Exploring refined clustering techniques to enhance data grouping accuracy.

![](/results/13_Kmeans_SVD.png)

### ğŸ“˜ **[Principal Component Analysis (PCA)](./Python_code/14_PCA.ipynb)**

**Method Used:** Principal Component Analysis (PCA) for dimensionality reduction.

**Problem Addressed:** Reducing high-dimensional data while preserving the most significant variance.

![](/results/14_PCA.png)

### ğŸ“˜ **[15 Eigenfaces](./Python_code/15_eigenfaces.ipynb)**

**Method Used:** Eigenfaces approach for facial recognition.

**Problem Addressed:** Identifying and recognizing faces using a reduced set of eigenvectors.

![](/results/15_eigenfaces.png)

### ğŸ“˜ **[Graph-based optimization](./Python_code/16_bucky.ipynb)**

**Method Used:** Graph-based optimization in machine learning.

**Problem Addressed:** Optimizing node connectivity and network efficiency using graph-based representations.

![](/results/16_bucky.png)

### ğŸ“˜ **[Color Image Compression](./Python_code/17_color_image_compression.ipynb)**

**Method Used:** Color image compression using matrix factorization.

**Problem Addressed:** Reducing the storage size of color images while maintaining visual quality.

![](/results/17_color_image_compression.png)

### ğŸ“˜ **[Matrix completion](./Python_code/18_matrix_completion.ipynb)**

**Method Used:** Matrix completion techniques for missing data imputation.

**Problem Addressed:** Predicting missing values in datasets using matrix factorization approaches.

### ğŸ“˜ **[Neural Network](./Python_code/19_neural_net.ipynb)**

**Method Used:** Neural networks for supervised learning.

**Problem Addressed:** Building and training a simple neural network for predictive modeling.

![](/results/19_neural_net.png)

### ğŸ“˜ **[Proximal Gradient Descent](./Python_code/20_proximal_gradient_descent.ipynb)**

**Method Used:** Optimization using proximal gradient descent.

**Problem Addressed:** Optimizing complex functions with sparsity constraints in high-dimensional settings.

![](/results/20_proximal_gradient_descent.png)


### ğŸ“˜ **[L1 regularized optimization](./Python_code/21_proximal_gradient_descent_l1.ipynb)**

**Method Used:** L1 regularized optimization with proximal gradient descent.

**Problem Addressed:** Applying L1 regularization to encourage sparsity in machine learning models.

![](/results/21_proximal_gradient_descent_l1.png)


### ğŸ“˜ **[## Two-neuron network](./Python_code/22_two_neuron.ipynb)**

**Method Used:** Two-neuron network for understanding activation functions.

**Problem Addressed:** Exploring how different activation functions affect neural network behavior.

![](/results/22_two_neuron.png)


---

*This portfolio showcases my ability to implement advanced matrix-based techniques in machine learning. Thank you for visiting!*
